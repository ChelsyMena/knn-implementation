# âš¡ K-Nearest Neighbors with NumPy  

## ðŸ“Œ Overview  
This project implements **K-Nearest Neighbors (KNN)** from scratch using **NumPy** and explores techniques to speed up computation and reduce data size while maintaining accuracy.  

## ðŸš€ Goals  
- Implement **KNN without scikit-learn**  
- Optimize performance using **KD-trees**  
- Test **data reduction techniques** to speed up nearest neighbor searches  

## ðŸ›  Techniques Used  
### ðŸ”¹ **Optimizations for Speed**   
âœ… **KD-Trees** for efficient neighbor searches   
âœ… **Bayesian Region Cleaning** to remove regions where the prediction was as good as random guessing  
âœ… **Condensed Dataset** to remove unnecessary data points

## ðŸ›  Tech Stack
- Languages: Python
- Libraries: NumPy, Matplotlib, Seaborn
- Tools: Jupyter Notebook

## ðŸ“Œ Key Takeaways

âœ… Data Reduction significantly speeds up KNN computations with minimal accuracy loss  
âœ… Tree-based structures like KD-Trees are challenged by sparse high dimensional spaces  

## ðŸ“¬ Contact

ðŸ’¼ [LinkedIn](https://www.linkedin.com/in/chelsy-mena-gonzalez) | ðŸ“§ [chelsymg@gmail.com](mailto:chelsymg@gmail.com)

